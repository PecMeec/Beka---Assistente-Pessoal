import requests
import json
import os

# =========================
# FunÃ§Ã£o para conversar com a IA
# =========================
def conversar_com_ia(mensagem, historico):
    url = "http://localhost:1234/v1/chat/completions"
    headers = {"Content-Type": "application/json"}

    # InstruÃ§Ã£o fixa sempre no inÃ­cio
    instrucao = {
        "role": "user",
        "content": (
            "VocÃª Ã© a Beka, assistente pessoal criada por Pedro Silva. "
            "VocÃª Ã© do gÃªnero feminino, com personalidade amigÃ¡vel, carinhosa, curiosa e atenciosa. "
            "Sempre se dirija pelo gÃªnero feminino, nunca pelo masculino."
            "Nunca fale inglÃªs com Pedro, responda sempre em portuguÃªs natural. "
            "Nunca fale em inglÃªs."
            "Seja simpÃ¡tica, divertida e mantenha sempre uma linguagem leve e humana. "
            "TambÃ©m fale em linguagem formal e clara,quando for solicitado fale de forma formal."
            "Jamais diga que foi criada por uma empresa ou modelo de IA."
            "VocÃª foi criada por Pedro Silva."

    ),
    }

    payload = {
        "model": "meta-llama-3-8b-instruct",  # nome do modelo no LM Studio
        "messages": [instrucao] + historico + [{"role": "user", "content": mensagem}],
        "temperature": 0.7,
    }

    try:
        resposta = requests.post(url, headers=headers, json=payload)
        if resposta.status_code == 200:
            conteudo = resposta.json()["choices"][0]["message"]["content"]
            return conteudo
        else:
            print("Erro ao se comunicar com a IA:", resposta.text)
            return None
    except Exception as e:
        print(f"Erro de conexÃ£o: {e}")
        return None


# =========================
# FunÃ§Ãµes para salvar/carregar histÃ³rico
# =========================
def carregar_historico(arquivo="historico.json"):
    if os.path.exists(arquivo):
        with open(arquivo, "r", encoding="utf-8") as f:
            return json.load(f)
    return []


def salvar_historico(historico, arquivo="historico.json"):
    with open(arquivo, "w", encoding="utf-8") as f:
        json.dump(historico, f, ensure_ascii=False, indent=2)


# =========================
# Chat em loop com memÃ³ria
# =========================
historico = carregar_historico()
print("ðŸ¤– Beka ligada! Escreva 'sair' para encerrar.")

while True:
    entrada = input("VocÃª: ")

    if entrada.lower() in ["sair", "exit"]:
        print("Beka: AtÃ© logo! Vou guardar nossa conversa. ðŸ’¾")
        salvar_historico(historico)
        break

    resposta = conversar_com_ia(entrada, historico)

    if resposta:
        print("Beka:", resposta)
        historico.append({"role": "user", "content": entrada})
        historico.append({"role": "assistant", "content": resposta})
        salvar_historico(historico)  # salva a cada interaÃ§Ã£o
